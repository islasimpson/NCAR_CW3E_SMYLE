{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xesmf as xe\n",
    "import warnings\n",
    "import dask\n",
    "import sys\n",
    "\n",
    "from CASutils import calendar_utils as cal\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x2b491372a518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({'distributed.dashboard.link': 'https://jupyterhub.ucar.edu/dav/user/{USER}/proxy/{port}/status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "dask.config.set({\"distributed.scheduler.worker_saturation\":\"1.0\"})\n",
    "\n",
    "cluster = PBSCluster(\n",
    "    cores = 1,\n",
    "    memory = '30GB',\n",
    "    processes = 1,\n",
    "    queue = 'casper',\n",
    "    local_directory = '$TMPDIR',\n",
    "    resource_spec = 'select=1:ncpus=1:mem=20GB',\n",
    "    project='P04010022',\n",
    "    walltime='12:00:00',\n",
    "    interface='ib0')\n",
    "\n",
    "# scale up\n",
    "cluster.scale(24)\n",
    "\n",
    "# change your urls to the dask dashboard so that you can see it\n",
    "dask.config.set({'distributed.dashboard.link':'https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/proxy/{port}/status'})\n",
    "\n",
    "# Setup your client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the workers going\n",
    "#ncores = 36\n",
    "#nmem = '460GB'\n",
    "#nmem = str(int(365*ncores/36))+'GB'\n",
    "#from dask_jobqueue import SLURMCluster\n",
    "#from dask.distributed import Client\n",
    "#cluster = SLURMCluster(cores=ncores,\n",
    "#                     processes=ncores, memory=nmem,\n",
    "#                     project='P04010022',\n",
    "#                     walltime='12:00:00')\n",
    "#cluster.scale(ncores)\n",
    "#client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>PBSCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Dashboard: </b><a href='https://jupyterhub.hpc.ucar.edu/stable/user/islas/proxy/8787/status' target='_blank'>https://jupyterhub.hpc.ucar.edu/stable/user/islas/proxy/8787/status</a>\n",
       "  </ul>\n",
       "</div>\n"
      ],
      "text/plain": [
       "PBSCluster('tcp://10.12.206.54:37065', workers=16, threads=16, memory=343.60 GB)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.12.206.54:37065</li>\n",
       "  <li><b>Dashboard: </b><a href='https://jupyterhub.hpc.ucar.edu/stable/user/islas/proxy/8787/status' target='_blank'>https://jupyterhub.hpc.ucar.edu/stable/user/islas/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>343.60 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.12.206.54:37065' processes=16 threads=16, memory=343.60 GB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do this until you see you've got some workers\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of ERA5 data on RDA\n",
    "filepath=\"/gpfs/fs1/collections/rda/data/ds633.0/e5.oper.an.pl/\"\n",
    "# output location\n",
    "outpath=\"/glade/scratch/islas/processed/era5/TEMdiags/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystart=2021 ; yend=2021 ; nyears=yend-ystart+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up CESM data to get the output grid.\n",
    "cesmdat = xr.open_dataset(\"/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/PHIS/f.e11.F1850C5CNTVSST.f09_f09.002.cam.h0.PHIS.040101-050012.nc\")\n",
    "grid_out = xr.Dataset({'lat': (['lat'], cesmdat.lat)}, {'lon': (['lon'], cesmdat.lon)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01\n",
      "2021-02\n",
      "2021-03\n",
      "2021-04\n",
      "2021-05\n",
      "2021-06\n",
      "2021-07\n",
      "2021-08\n",
      "2021-09\n",
      "2021-10\n",
      "2021-11\n",
      "2021-12\n",
      "CPU times: user 4min 7s, sys: 38.1 s, total: 4min 46s\n",
      "Wall time: 1h 10min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reusewgt=False\n",
    "wgtfile=outpath+\"wgtfile.nc\"\n",
    "for iyear in range(ystart,yend+1,1):\n",
    "    #for imon in range(1,13,1):\n",
    "    for imon in range(1,13,1):\n",
    "    #for imon in range(11,13,1):\n",
    "        monstr=str(imon).zfill(2)\n",
    "        print(str(iyear)+\"-\"+monstr)\n",
    "        \n",
    "        ds = xr.open_mfdataset(\n",
    "        filepath + str(iyear)+monstr+ \"/*_[u, v, w, t].*.nc\",\n",
    "        coords=\"minimal\",\n",
    "        join=\"override\",\n",
    "        decode_times=True,\n",
    "        use_cftime=True,\n",
    "        chunks={\"time\":24, \"level\":15},\n",
    "        parallel=True,\n",
    "        data_vars = \"minimal\",\n",
    "        compat = \"override\")\n",
    "        \n",
    "        ds = ds.set_coords(\"utc_date\")\n",
    "        \n",
    "        dayspermon = ds.time.dt.daysinmonth.data\n",
    "        dayendstr = str(dayspermon[0])\n",
    "        timeout = pd.date_range(\n",
    "            start=str(iyear)+\"-\"+monstr+\"-01\",\n",
    "            end=str(iyear)+\"-\"+monstr+\"-\"+dayendstr)\n",
    "        \n",
    "        ds = ds.loc[{\"time\": ds.time.dt.hour.isin([0,6,12,18])}]\n",
    "             \n",
    "        # convert to theta\n",
    "        ds[\"T\"] = ds.T * (ds.T.level / 1000.0)**(-2./7.)\n",
    "        # convert Pa/s to m/s\n",
    "        #!!!! Isla 08/30/21 - I think this still isn't right.  I think ds.W.level is in hPa instead of Pa\n",
    "        #!!!! Isla 02/09/21 - Now I think this is right.  Added in *100 after dz.W.level\n",
    "        g=9.81\n",
    "        rgas=287.058\n",
    "        ds[\"W\"] = -1.*ds.W/ ( g * ((ds.W.level*100.)/(rgas*ds.T))) \n",
    "        ds[\"W\"].attrs={'long_name':'Zonal-Mean vertical velocity','units':'m/s'}\n",
    "        #!!!! I think this is wrong as I've already converted T to potential T here. (27th Feb 2023)\n",
    "        \n",
    "        \n",
    "        \n",
    "        regridder = xe.Regridder(ds.U, grid_out, 'bilinear', periodic=True, \n",
    "                                 reuse_weights=reusewgt, filename=wgtfile)\n",
    "        reusewgt = True\n",
    "        \n",
    "        regridded = regridder(ds).persist()\n",
    "        \n",
    "        # this was causing issues before.  Either need to compute the zonal mean before\n",
    "        # subtracting or do the persist on the regridded above.\n",
    "        zonal_means = regridded.mean(\"lon\")\n",
    "        anomaly = regridded - zonal_means\n",
    "        \n",
    "        anomaly['uv'] = anomaly.U*anomaly.V\n",
    "        anomaly['vt'] = anomaly.V*anomaly.T\n",
    "        anomaly['uw'] = anomaly.U*anomaly.W\n",
    "        \n",
    "        zonal_means = zonal_means.merge(anomaly[['uv','vt','uw']].mean(\"lon\"))\n",
    "        \n",
    "        temdiags = zonal_means.rename(\n",
    "            {\n",
    "                \"uv\":\"UVzm\",\n",
    "                \"vt\":\"VTHzm\",\n",
    "                \"uw\":\"UWzm\",\n",
    "                \"U\":\"Uzm\",\n",
    "                \"V\":\"Vzm\",\n",
    "                \"W\":\"Wzm\",\n",
    "                \"T\":\"THzm\",\n",
    "            })\n",
    "        \n",
    "        temdiags.UVzm.attrs={'units':'m2/s2'}\n",
    "        temdiags.VTHzm.attrs={'units':'Km/s'}\n",
    "        temdiags.UWzm.attrs={'units':'m2/s2'}\n",
    "        temdiags.Uzm.attrs={'units':'m/s'}\n",
    "        temdiags.Vzm.attrs={'units':'m/s'}\n",
    "        temdiags.Wzm.attrs={'units':'m/s'}\n",
    "        temdiags.THzm.attrs={'units':'K'}\n",
    "        \n",
    "        temdiags = temdiags.groupby('time.dayofyear').mean()\n",
    "        temdiags = temdiags.rename({'dayofyear':'time'})\n",
    "        temdiags['time'] = timeout\n",
    "        outfile = outpath+\"fluxes_\"+str(iyear)+\"-\"+monstr+\".nc\"\n",
    "        # Since temdiags is small, it's better to load it and write in serial than in\n",
    "        # parallel to netcdf.\n",
    "        temdiags.load().to_netcdf(path=outfile)\n",
    "        \n",
    "        client.cancel(regridded) # deleted from distriubted RAM to recover memory\n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temdiags.load().to_netcdf(path=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataArray' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c7cdd0643fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemdiags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'units'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'days since '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miyear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ecpaperenv/lib/python3.6/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "temdiags.time.encode['units'] = 'days since '+str(iyear)+'-'+str(imon).zfill(2)+'-'+str(imon).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temdiags['time'] = timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 31)>\n",
      "array(['1959-01-01T00:00:00.000000000', '1959-01-02T00:00:00.000000000',\n",
      "       '1959-01-03T00:00:00.000000000', '1959-01-04T00:00:00.000000000',\n",
      "       '1959-01-05T00:00:00.000000000', '1959-01-06T00:00:00.000000000',\n",
      "       '1959-01-07T00:00:00.000000000', '1959-01-08T00:00:00.000000000',\n",
      "       '1959-01-09T00:00:00.000000000', '1959-01-10T00:00:00.000000000',\n",
      "       '1959-01-11T00:00:00.000000000', '1959-01-12T00:00:00.000000000',\n",
      "       '1959-01-13T00:00:00.000000000', '1959-01-14T00:00:00.000000000',\n",
      "       '1959-01-15T00:00:00.000000000', '1959-01-16T00:00:00.000000000',\n",
      "       '1959-01-17T00:00:00.000000000', '1959-01-18T00:00:00.000000000',\n",
      "       '1959-01-19T00:00:00.000000000', '1959-01-20T00:00:00.000000000',\n",
      "       '1959-01-21T00:00:00.000000000', '1959-01-22T00:00:00.000000000',\n",
      "       '1959-01-23T00:00:00.000000000', '1959-01-24T00:00:00.000000000',\n",
      "       '1959-01-25T00:00:00.000000000', '1959-01-26T00:00:00.000000000',\n",
      "       '1959-01-27T00:00:00.000000000', '1959-01-28T00:00:00.000000000',\n",
      "       '1959-01-29T00:00:00.000000000', '1959-01-30T00:00:00.000000000',\n",
      "       '1959-01-31T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1959-01-01 1959-01-02 ... 1959-01-31\n"
     ]
    }
   ],
   "source": [
    "print(temdiags.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 31)>\n",
      "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\n",
      "Coordinates:\n",
      "  * time     (time) int64 1 2 3 4 5 6 7 8 9 10 ... 22 23 24 25 26 27 28 29 30 31\n"
     ]
    }
   ],
   "source": [
    "print(temdiags.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['1959-01-01', '1959-01-02', '1959-01-03', '1959-01-04',\n",
      "               '1959-01-05', '1959-01-06', '1959-01-07', '1959-01-08',\n",
      "               '1959-01-09', '1959-01-10', '1959-01-11', '1959-01-12',\n",
      "               '1959-01-13', '1959-01-14', '1959-01-15', '1959-01-16',\n",
      "               '1959-01-17', '1959-01-18', '1959-01-19', '1959-01-20',\n",
      "               '1959-01-21', '1959-01-22', '1959-01-23', '1959-01-24',\n",
      "               '1959-01-25', '1959-01-26', '1959-01-27', '1959-01-28',\n",
      "               '1959-01-29', '1959-01-30', '1959-01-31'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "print(timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
